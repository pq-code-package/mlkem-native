#!/usr/bin/env python3
# Copyright (c) 2024 The mlkem-native project authors
# SPDX-License-Identifier: Apache-2.0

import subprocess
import argparse
import glob
import sys
import os

modulus = 3329
root_of_unity = 17
montgomery_factor = pow(2, 16, modulus)

# This file re-generated auto-generated source files in mlkem-native.
#
# It currently covers:
# - zeta values for the reference NTT and invNTT
# - lookup tables used for fast rejection sampling
# - source files for monolithic single-CU build


def gen_header():
    yield "/*"
    yield " * Copyright (c) 2024 The mlkem-native project authors"
    yield " * SPDX-License-Identifier: Apache-2.0"
    yield " */"
    yield ""
    yield "/*"
    yield " * WARNING: This file is auto-generated from scripts/autogen"
    yield " *          Do not modify it directly."
    yield " */"
    yield ""


def update_file(filename, content, dry_run=False):

    # Format content
    p = subprocess.run(
        ["clang-format"], capture_output=True, input=content, text=True, shell=True
    )
    if p.returncode != 0:
        print(p.stderr)
        print(
            f"Failed to auto-format autogenerated code (clang-format return code {p.returncode}). Are you running in a nix shell? See BUILDING.md."
        )
        exit(1)
    content = p.stdout

    if dry_run is False:
        with open(filename, "w+") as f:
            f.write(content)
    else:
        if os.path.exists(filename) is False:
            print(f"Autogenerated file {filename} does not exist")
            exit(1)
        with open(filename, "r") as f:
            current_content = f.read()
        if current_content != content:
            filename_new = f"{filename}.new"
            print(
                f"Autogenerated file {filename} needs updating. Have you called scripts/autogenerated.py?",
                file=sys.stderr,
            )
            print(f"Writing new version to {filename_new}", file=sys.stderr)
            with open(filename_new, "w") as f:
                f.write(content)
            subprocess.run(["diff", filename, filename_new])
            exit(1)


def bitreverse(i, n):
    r = 0
    for _ in range(n):
        r = 2 * r + (i & 1)
        i >>= 1
    return r


def signed_reduce(a):
    """Return signed canonical representative of a mod b"""
    c = a % modulus
    if c >= modulus / 2:
        c -= modulus
    return c


def gen_c_zetas():
    """Generate source and header file for zeta values used in
    the reference NTT and invNTT"""

    # The zeta values are the powers of the chosen root of unity (17),
    # converted to Montgomery form.

    zeta = []
    for i in range(128):
        zeta.append(signed_reduce(pow(root_of_unity, i, modulus) * montgomery_factor))

    # The source code stores the zeta table in bit reversed form
    yield from (zeta[bitreverse(i, 7)] for i in range(128))


def gen_c_zeta_file(dry_run=False):
    def gen():
        yield from gen_header()
        yield '#include "common.h"'
        yield "#if !defined(MLKEM_NATIVE_MULTILEVEL_BUILD_NO_SHARED)"
        yield '#include "poly.h"'
        yield ""
        yield "/*"
        yield " * Table of zeta values used in the reference NTT and inverse NTT."
        yield " * See autogen for details."
        yield " */"
        yield "ALIGN const int16_t zetas[128] = {"
        yield from map(lambda t: str(t) + ",", gen_c_zetas())
        yield "};"
        yield ""
        yield "#else /* MLKEM_NATIVE_MULTILEVEL_BUILD_NO_SHARED */"
        yield ""
        yield "MLKEM_NATIVE_EMPTY_CU(zetas)"
        yield ""
        yield "#endif /* MLKEM_NATIVE_MULTILEVEL_BUILD_NO_SHARED */"
        yield ""

    update_file("mlkem/zetas.c", "\n".join(gen()), dry_run=dry_run)


def prepare_root_for_barrett(root):
    """Takes a constant that the code needs to Barrett-multiply with,
    and returns the pair of (a) its signed canonical form, (b) the
    twisted constant used in the high-mul part of the Barrett multiplication."""

    # Signed canonical reduction
    root = signed_reduce(root)

    def round_to_even(t):
        rt = round(t)
        if rt % 2 == 0:
            return rt
        # Make sure to pick a rounding target
        # that's <= 1 away from x in absolute value.
        if rt <= t:
            return rt + 1
        return rt - 1

    root_twisted = round_to_even((root * 2**16) / modulus) // 2
    return root, root_twisted


def gen_aarch64_root_of_unity_for_block(layer, block, inv=False):
    # We are computing a negacyclic NTT; the twiddles needed here is
    # the second half of the twiddles for a cyclic NTT of twice the size.
    log = bitreverse(pow(2, layer) + block, 7)
    if inv is True:
        log = -log
    root, root_twisted = prepare_root_for_barrett(pow(root_of_unity, log, modulus))
    return root, root_twisted


def gen_aarch64_fwd_ntt_zetas_layer01234():
    # Layers 0,1,2 are merged
    yield from gen_aarch64_root_of_unity_for_block(0, 0)
    yield from gen_aarch64_root_of_unity_for_block(1, 0)
    yield from gen_aarch64_root_of_unity_for_block(1, 1)
    yield from gen_aarch64_root_of_unity_for_block(2, 0)
    yield from gen_aarch64_root_of_unity_for_block(2, 1)
    yield from gen_aarch64_root_of_unity_for_block(2, 2)
    yield from gen_aarch64_root_of_unity_for_block(2, 3)
    yield from (0, 0)  # Padding

    # Layers 3,4,5,6 are merged, but we emit roots for 3,4
    # in separate arrays than those for 5,6
    for block in range(8):  # There are 8 blocks in Layer 4
        yield from gen_aarch64_root_of_unity_for_block(3, block)
        yield from gen_aarch64_root_of_unity_for_block(4, 2 * block + 0)
        yield from gen_aarch64_root_of_unity_for_block(4, 2 * block + 1)
        yield from (0, 0)  # Padding


def gen_aarch64_fwd_ntt_zetas_layer56():
    # Layers 3,4,5,6 are merged, but we emit roots for 3,4
    # in separate arrays than those for 5,6
    for block in range(8):

        def double_ith(t, i):
            yield from (t[i], t[i])

        # Ordering of blocks is adjusted to suit the transposed internal
        # presentation of the data
        for i in range(2):
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(5, 4 * block + 0), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(5, 4 * block + 1), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(5, 4 * block + 2), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(5, 4 * block + 3), i
            )
        for i in range(2):
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 0), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 2), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 4), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 6), i
            )
        for i in range(2):
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 1), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 3), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 5), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 7), i
            )


def gen_aarch64_inv_ntt_zetas_layer01234():
    # Layers 3,4,5,6 are merged, but we emit roots for 3,4
    # in separate arrays than those for 5,6
    for block in range(8):  # There are 8 blocks in Layer 4
        yield from gen_aarch64_root_of_unity_for_block(3, block, inv=True)
        yield from gen_aarch64_root_of_unity_for_block(4, 2 * block + 0, inv=True)
        yield from gen_aarch64_root_of_unity_for_block(4, 2 * block + 1, inv=True)
        yield from (0, 0)  # Padding

    # Layers 0,1,2 are merged
    yield from gen_aarch64_root_of_unity_for_block(0, 0, inv=True)
    yield from gen_aarch64_root_of_unity_for_block(1, 0, inv=True)
    yield from gen_aarch64_root_of_unity_for_block(1, 1, inv=True)
    yield from gen_aarch64_root_of_unity_for_block(2, 0, inv=True)
    yield from gen_aarch64_root_of_unity_for_block(2, 1, inv=True)
    yield from gen_aarch64_root_of_unity_for_block(2, 2, inv=True)
    yield from gen_aarch64_root_of_unity_for_block(2, 3, inv=True)
    yield from (0, 0)  # Padding


def gen_aarch64_inv_ntt_zetas_layer56():
    # Layers 3,4,5,6 are merged, but we emit roots for 3,4
    # in separate arrays than those for 5,6
    for block in range(8):

        def double_ith(t, i):
            yield from (t[i], t[i])

        # Ordering of blocks is adjusted to suit the transposed internal
        # presentation of the data
        for i in range(2):
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(5, 4 * block + 0, inv=True), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(5, 4 * block + 1, inv=True), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(5, 4 * block + 2, inv=True), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(5, 4 * block + 3, inv=True), i
            )
        for i in range(2):
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 0, inv=True), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 2, inv=True), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 4, inv=True), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 6, inv=True), i
            )
        for i in range(2):
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 1, inv=True), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 3, inv=True), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 5, inv=True), i
            )
            yield from double_ith(
                gen_aarch64_root_of_unity_for_block(6, 8 * block + 7, inv=True), i
            )


def gen_aarch64_mulcache_twiddles():
    for idx in range(64):
        root = pow(root_of_unity, bitreverse(64 + idx, 7), modulus)
        yield prepare_root_for_barrett(root)[0]
        yield prepare_root_for_barrett(-root)[0]


def gen_aarch64_mulcache_twiddles_twisted():
    for idx in range(64):
        root = pow(root_of_unity, bitreverse(64 + idx, 7), modulus)
        yield prepare_root_for_barrett(root)[1]
        yield prepare_root_for_barrett(-root)[1]


def gen_aarch64_fwd_ntt_zeta_file(dry_run=False):
    def gen():
        yield from gen_header()
        yield '#include "../../../common.h"'
        yield ""
        yield "#if defined(MLKEM_NATIVE_ARITH_BACKEND_AARCH64_CLEAN) || \\"
        yield "    defined(MLKEM_NATIVE_ARITH_BACKEND_AARCH64_OPT)"
        yield ""
        yield "#include <stdint.h>"
        yield '#include "arith_native_aarch64.h"'
        yield ""
        yield "/*"
        yield " * Table of zeta values used in the AArch64 forward NTT"
        yield " * See autogen for details."
        yield " */"
        yield "ALIGN const int16_t aarch64_ntt_zetas_layer01234[] = {"
        yield from map(lambda t: str(t) + ",", gen_aarch64_fwd_ntt_zetas_layer01234())
        yield "};"
        yield ""
        yield "ALIGN const int16_t aarch64_ntt_zetas_layer56[] = {"
        yield from map(lambda t: str(t) + ",", gen_aarch64_fwd_ntt_zetas_layer56())
        yield "};"
        yield ""
        yield "ALIGN const int16_t aarch64_invntt_zetas_layer01234[] = {"
        yield from map(lambda t: str(t) + ",", gen_aarch64_inv_ntt_zetas_layer01234())
        yield "};"
        yield ""
        yield "ALIGN const int16_t aarch64_invntt_zetas_layer56[] = {"
        yield from map(lambda t: str(t) + ",", gen_aarch64_inv_ntt_zetas_layer56())
        yield "};"
        yield ""
        yield "ALIGN const int16_t aarch64_zetas_mulcache_native[] = {"
        yield from map(lambda t: str(t) + ",", gen_aarch64_mulcache_twiddles())
        yield "};"
        yield ""
        yield "ALIGN const int16_t aarch64_zetas_mulcache_twisted_native[] = {"
        yield from map(lambda t: str(t) + ",", gen_aarch64_mulcache_twiddles_twisted())
        yield "};"
        yield ""
        yield "#else"
        yield ""
        yield "MLKEM_NATIVE_EMPTY_CU(aarch64_zetas)"
        yield ""
        yield "#endif"
        yield ""

    update_file(
        "mlkem/native/aarch64/src/aarch64_zetas.c", "\n".join(gen()), dry_run=dry_run
    )


def gen_aarch64_rej_uniform_table_rows():
    # The index into the lookup table is an 8-bit bitmap, i.e. a number 0..255.
    # Conceptually, the table entry at index i is a vector of 8 16-bit values, of
    # which only the first popcount(i) are set; those are the indices of the set-bits
    # in i. Concretely, we store each 16-bit index as consecutive 8-bit indices.
    def get_set_bits_idxs(i):
        bits = list(map(int, format(i, "08b")))
        bits.reverse()
        return [bit_idx for bit_idx in range(8) if bits[bit_idx] == 1]

    for i in range(256):
        idxs = get_set_bits_idxs(i)
        # Replace each index by two consecutive indices
        idxs = [j for i in idxs for j in [2 * i, 2 * i + 1]]
        # Pad by -1
        idxs = idxs + [-1] * (16 - len(idxs))
        yield ",".join(map(str, idxs)) + f" /* {i} */"


def gen_aarch64_rej_uniform_table(dry_run=False):
    def gen():
        yield from gen_header()
        yield '#include "../../../common.h"'
        yield ""
        yield "#if defined(MLKEM_NATIVE_ARITH_BACKEND_AARCH64_CLEAN) || \\"
        yield "    defined(MLKEM_NATIVE_ARITH_BACKEND_AARCH64_OPT)"
        yield ""
        yield "#include <stdint.h>"
        yield '#include "arith_native_aarch64.h"'
        yield ""
        yield "/*"
        yield " * Lookup table used by rejection sampling of the public matrix."
        yield " * See autogen for details."
        yield " */"
        yield "ALIGN const uint8_t rej_uniform_table[] = {"
        yield from map(lambda t: str(t) + ",", gen_aarch64_rej_uniform_table_rows())
        yield "};"
        yield ""
        yield "#else"
        yield ""
        yield "MLKEM_NATIVE_EMPTY_CU(aarch64_rej_uniform_table)"
        yield ""
        yield "#endif"
        yield ""

    update_file(
        "mlkem/native/aarch64/src/rej_uniform_table.c",
        "\n".join(gen()),
        dry_run=dry_run,
    )


def gen_avx2_rej_uniform_table_rows():
    # The index into the lookup table is an 8-bit bitmap, i.e. a number 0..255.
    # Conceptually, the table entry at index i is a vector of 8 16-bit values, of
    # which only the first popcount(i) are set; those are the indices of the set-bits
    # in i.
    def get_set_bits_idxs(i):
        bits = list(map(int, format(i, "08b")))
        bits.reverse()
        return [bit_idx for bit_idx in range(8) if bits[bit_idx] == 1]

    for i in range(256):
        idxs = get_set_bits_idxs(i)
        idxs = [2 * i for i in idxs]
        # Pad by -1
        idxs = idxs + [-1] * (8 - len(idxs))
        yield "{" + ",".join(map(str, idxs)) + "}"


def gen_avx2_rej_uniform_table(dry_run=False):
    def gen():
        yield from gen_header()
        yield '#include "../../../common.h"'
        yield ""
        yield "#if defined(MLKEM_NATIVE_ARITH_BACKEND_X86_64_DEFAULT)"
        yield ""
        yield "#include <stdint.h>"
        yield '#include "arith_native_x86_64.h"'
        yield ""
        yield "/*"
        yield " * Lookup table used by rejection sampling of the public matrix."
        yield " * See autogen for details."
        yield " */"
        yield "ALIGN const uint8_t rej_uniform_table[256][8] = {"
        yield from map(lambda t: str(t) + ",", gen_avx2_rej_uniform_table_rows())
        yield "};"
        yield ""
        yield "#else"
        yield ""
        yield "MLKEM_NATIVE_EMPTY_CU(avx2_rej_uniform_table)"
        yield ""
        yield "#endif"
        yield ""

    update_file(
        "mlkem/native/x86_64/src/rej_uniform_table.c",
        "\n".join(gen()),
        dry_run=dry_run,
    )


def signed_reduce_u16(x):
    x = x % 2**16
    if x >= 2**15:
        x -= 2**16
    return x


def prepare_root_for_montmul(root):
    """Takes a constant that the code needs to Montgomery-multiply with,
    and returns the pair of (a) the signed canonical representative of its
    Montgomery form, (b) the twisted constant used in the low-mul part of
    the Montgomery multiplication."""

    # Convert to Montgomery form and pick canonical signed representative
    root = signed_reduce(root * montgomery_factor)
    root_twisted = signed_reduce_u16(root * pow(modulus, -1, 2**16))
    return root, root_twisted


def gen_avx2_root_of_unity_for_block(layer, block, inv=False):
    # We are computing a negacyclic NTT; the twiddles needed here is
    # the second half of the twiddles for a cyclic NTT of twice the size.
    log = bitreverse(pow(2, layer) + block, 7)
    if inv is True:
        log = -log
    root, root_twisted = prepare_root_for_montmul(pow(root_of_unity, log, modulus))
    return root, root_twisted


def gen_avx2_fwd_ntt_zetas():

    def gen_twiddles(layer, block, repeat):
        """Generates twisted twiddle, then twiddle, for given layer and block.
        Repeat both the given number of times."""
        root, root_twisted = gen_avx2_root_of_unity_for_block(layer, block)
        return [root] * repeat, [root_twisted] * repeat

    def gen_twiddles_many(layer, block_base, block_offsets, repeat):
        """Generates twisted twiddles, then twiddles, of each (layer, block_base + i)
        pair for i in block_offsets. Each twiddle is repeated `repeat` times."""
        root_pairs = list(
            map(lambda x: gen_twiddles(layer, block_base + x, repeat), block_offsets)
        )
        yield from (r for l in root_pairs for r in l[1])
        yield from (r for l in root_pairs for r in l[0])

    # Layers 0 twiddle
    yield from gen_twiddles_many(0, 0, range(1), 4)
    # Padding so that the subsequent twiddles are 16-byte aligned
    yield from [0] * 8

    # Layer 1-6 twiddles, separated by whether they belong to the upper or lower half
    for i in range(2):
        yield from gen_twiddles_many(1, i * (2**0), range(1), 16)
        yield from gen_twiddles_many(2, i * (2**1), range(2), 8)
        yield from gen_twiddles_many(3, i * (2**2), range(4), 4)
        yield from gen_twiddles_many(4, i * (2**3), range(8), 2)
        yield from gen_twiddles_many(5, i * (2**4), range(16), 1)
        yield from gen_twiddles_many(6, i * (2**5), range(0, 32, 2), 1)
        yield from gen_twiddles_many(6, i * (2**5), range(1, 32, 2), 1)


def gen_avx2_fwd_ntt_zeta_file(dry_run=False):
    def gen():
        yield from gen_header()
        yield "/*"
        yield " * Table of zeta values used in the AVX2 NTTs"
        yield " * See autogen for details."
        yield " */"
        yield ""
        yield from map(lambda t: str(t) + ",", gen_avx2_fwd_ntt_zetas())
        yield ""

    update_file(
        "mlkem/native/x86_64/src/x86_64_zetas.i", "\n".join(gen()), dry_run=dry_run
    )


def get_c_source_files():
    return get_files("mlkem/*.c")


def get_asm_source_files():
    return get_files("mlkem/*.S")


def get_header_files():
    return get_files("mlkem/*.h")


def get_files(pattern):
    cmd = ["git", "ls-files", f":{pattern}"]
    p = subprocess.run(cmd, capture_output=True)
    if p.returncode != 0:
        print(
            f"Failed to run {' '.join(cmd)}, error code {p.returncode}", file=sys.stderr
        )
        print(p.stderr.decode(), file=sys.stderr)
        exit(1)
    files = filter(lambda s: s != "", p.stdout.decode().split("\n"))
    return list(files)


def get_defines():
    for c in get_c_source_files() + get_header_files():
        with open(c, "r") as f:
            for l in f.read().split("\n"):
                if l.lstrip().startswith("#define "):
                    yield (
                        c,
                        l.lstrip()
                        .removeprefix("#define ")
                        .split(" ")[0]
                        .split("(")[0]
                        .replace("'", ""),
                    )

def get_checked_defines():
    allow_list = [("__contract__", "cbmc.h"),
                  ("__loop__", "cbmc.h")]

    def is_allowed(d,c):
        for (d0,c0) in allow_list:
            if c.endswith(c0) is True and d0 == d:
                return True
        return False

    for (c,d) in get_defines():
        if d.startswith("_") and is_allowed(d,c) is False:
            raise Exception(f"{d} from {c}:{i} starts with an underscore, which is not allowed for mlkem-native macros. "
                  f"If this is an mlkem-native specific macro, please pick a different name. "
                  f"If this is an external macro, it likely needs removing from `gen_monolithic_undef_all_core()` in `scripts/autogen` -- check this!")
        yield (c,d)

def gen_monolithic_undef_all_core(filt=None):

    if filt is None:
        filt = lambda c: True

    yield ""
    yield "/*"
    yield " * Undo all #define directives from *.c or *.h files"
    yield " */"
    yield ""

    def undo_define(filename, d):
        yield f"/* {filename} */"
        yield f"#if defined({d})"
        yield f"#undef {d}"
        yield "#endif"
        yield ""

    defines = list(set(get_checked_defines()))
    defines.sort()

    for filename, d in defines:
        if filt(filename) is False:
            continue
        yield from undo_define(filename, d)


def gen_monolithic_source_file(dry_run=False):

    def not_native(c):
        return "native/" not in c

    # List of level-specific source files
    # All other files only need including and building once
    # in multilevel build.
    def k_specific(c):
        # For now, we exclude native files from the monobuild
        if not_native(c) is False:
            return False

        k_specific_sources = ["mlkem_native.h", "params.h", "config.h", "common.h",
                              "indcpa.c", "indcpa.h",
                              "kem.c", "kem.h",
                              "poly_k.c", "poly_k.h" ]
        for f in k_specific_sources:
            if c.endswith(f):
                return True
        return False

    def k_generic(c):
        # For now, we exclude native files from the monobuild
        if not_native(c) is False:
            return False

        return not k_specific(c)

    def gen():
        yield from gen_header()
        yield "/*"
        yield " * Monolithic compilation unit bundling all compilation units within mlkem-native"
        yield " */"
        yield ""
        for c in filter(not_native, get_c_source_files()):
            yield f'#include "{c}"'
        yield ""
        yield from gen_monolithic_undef_all_core(filt=k_specific)
        yield ""
        yield "#if !defined(MLKEM_NATIVE_MONOBUILD_KEEP_SHARED_HEADERS)"
        yield from gen_monolithic_undef_all_core(filt=k_generic)
        yield "#endif /* MLKEM_NATIVE_MONOBUILD_KEEP_SHARED_HEADERS */"
        yield ""

    update_file(
        "examples/monolithic_build/mlkem_native_monobuild.c",
        "\n".join(gen()),
        dry_run=dry_run,
    )

def check_asm_register_aliases_for_file(filename):
    """Checks that `filename` has no mismatching or dangling register aliases"""

    def get_alias_def(l):
        s = list(filter(lambda s: s != "", l.strip().split(" ")))
        if len(s) < 3 or s[1] != ".req":
            return None
        return s[0]

    def get_alias_undef(l):
        if l.strip().startswith(".unreq") is False:
            return None
        return list(filter(lambda s: s != "", l.strip().split(" ")))[1]

    with open(filename, "r") as f:
        content = f.read()
    aliases = {}
    for i, l in enumerate(content.split('\n')):
        alias_def = get_alias_def(l)
        alias_undef = get_alias_undef(l)
        if alias_def is not None:
            if alias_def in aliases.keys():
                raise Exception(f"Invalid assembly file {filename}: Duplicate .req directive for {alias_def} at line {i}")
            aliases[alias_def] = i
        elif alias_undef is not None:
            if alias_undef not in aliases.keys():
                raise Exception(f"Invalid assembly file {filename}: .unreq without prior .req for {alias_undef} at line {i}")
            del aliases[alias_undef]

    if len(aliases) > 0:
        fixup_suggestion = ["/****************** REGISTER DEALLOCATIONS *******************/"]
        dangling = list(aliases.items())
        # Sort by line number of .req
        dangling.sort(key=lambda s: s[1])

        for a, _ in dangling:
            fixup_suggestion.append(f"    .unreq {a}")
        fixup_suggestion.append("")
        fixup_suggestion = '\n'.join(fixup_suggestion)

        raise Exception(f"Invalid assembly file {filename}: Dangling .req directives {aliases}.\n\nTry adding this?\n\n{fixup_suggestion}")

def check_asm_register_aliases():
    for asm_file in get_asm_source_files():
        check_asm_register_aliases_for_file(asm_file)



def _main():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument("--dry-run", default=False, action="store_true")

    args = parser.parse_args()

    check_asm_register_aliases()

    gen_c_zeta_file(args.dry_run)
    gen_aarch64_fwd_ntt_zeta_file(args.dry_run)
    gen_aarch64_rej_uniform_table(args.dry_run)
    gen_avx2_fwd_ntt_zeta_file(args.dry_run)
    gen_avx2_rej_uniform_table(args.dry_run)

    gen_monolithic_source_file(args.dry_run)


if __name__ == "__main__":
    _main()
