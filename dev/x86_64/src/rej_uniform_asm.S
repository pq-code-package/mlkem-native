/*
 * Copyright (c) The mlkem-native project authors
 * SPDX-License-Identifier: Apache-2.0 OR ISC OR MIT
 */

/*************************************************
 * Name:        mlk_rej_uniform_asm
 *
 * Description: Run rejection sampling on uniform random bytes to generate
 *              uniform random integers mod q
 *
 * Arguments:   - int16_t *r:          pointer to output buffer of MLKEM_N
 *                                     16-bit coefficients.
 *              - const uint8_t *buf:  pointer to input buffer
 *                                     (assumed to be uniform random bytes)
 *              - unsigned buflen:     length of input buffer in bytes.
 *                                     Must be a multiple of 12.
 *
 * Returns number of sampled 16-bit integers (at most MLKEM_N).
 **************************************************/
#include "../../../common.h"

#if defined(MLK_ARITH_BACKEND_X86_64_DEFAULT) && \
    !defined(MLK_CONFIG_MULTILEVEL_NO_SHARED)
/* simpasm: header-end */

#define in %rsi
#define out %rdi
#define len %rdx
#define tab %rcx

#define cnt %rax
#define pos %r8

#define good %r11
#define pext_mask %r9
#define table_idx %r10

#define bound %xmm0
#define temp0 %xmm1
#define temp1 %xmm6
#define vals %xmm2
#define shuffle_out_mask %xmm3
#define shuffle_in_mask %xmm4
#define and_mask %xmm5

//  High level overview of the algorithm:
//  For every 96 bits (12 bytes) of the input:
//    1. Split 96 bits into eight 12-bit integers where each integer
//       occupies a corresponding 16-bit element of `vals` xmm register,
//    2. Compute an 8-bit value `good` such that
//         good[i] = vals[i] < MLKEM_Q ? 1 : 0, for i in [0, 7],
//    3. Shuffle the elements in `vals` such that all good elements
//       are ordered consecutivelly, and store them.
//
//  Notes:
//    - We exit early if we find the required number of good values,
//    - We use the stack as a temporary storage and copy to the actual
//      output buffer only in the end. This is because the algorithm
//      can overwrite up to 14 bytes (we use 16B for alignment),
//    - The implementation uses x86 SSE and BMI2 extensions.

#define STACK_SIZE (2*MLKEM_N + 16)

.text
.global MLK_ASM_NAMESPACE(rej_uniform_asm)
.balign 4
MLK_ASM_FN_SYMBOL(rej_uniform_asm)
  .cfi_startproc
  subq $STACK_SIZE, %rsp
  .cfi_adjust_cfa_offset STACK_SIZE

  // Broadcast MLKEM_Q (3329) to all 16-bit elements of bound reg.
  movq $0x0D010D010D010D01, %rax
  movq %rax, bound
  pinsrq $1, %rax, bound

  // Broadcast 12-bit mask 0xFFF to all 16-bit elements of bound reg.
  movq $0x0FFF0FFF0FFF0FFF, %rax
  movq %rax, and_mask
  pinsrq $1, %rax, and_mask

  // Load shuffle mask:
  //   0, 1, 1, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 10, 11.
  movq $0x0504040302010100, %rax
  movq %rax, shuffle_in_mask
  movq $0x0B0A0A0908070706, %rax
  pinsrq $1, %rax, shuffle_in_mask

  movq $0, cnt // cnt counts the number of good values we've found.
  movq $0, pos // pos is the current position in the input buffer.
  movq $0x5555, pext_mask // 0x5555 mask to extract every second bit.

Lrej_uniform_asm_loop_start:
  // 1. Split 96 bits into eight 12-bit integers where each integer.
  //    We explain the algorithm by considering the lowest 64 bits of vals.
  movdqu  (in, pos), vals
  //    vals: [ 63..48 | 47..32 | 31..16 | 15..0 ]
  pshufb  shuffle_in_mask, vals
  //    vals: [ 47..32 | 39..24 | 23..8 | 15..0 ]
  movdqa  vals, temp1
  //    temp: [ 47..32 | 39..24 | 23..8 | 15..0 ]
  psrlw   $4, temp1
  //    temp: [ 47..36 | 39..28 | 23..12 | 15..4 ]
  pblendw $0xAA, temp1, vals
  //    vals: [ 47..36 | 39..24 | 23..12 | 15..0]
  pand    and_mask, vals
  //    vals: [ 47..36 | 35..24 | 23..12 | 12..0]

  // 2. Compute an 8-bit value `good` such that
  //      good[i] = vals[i] < MLKEM_Q ? 1 : 0, for i in [0, 7],
  movdqa   bound, temp0
  pcmpgtw  vals, temp0
  pmovmskb temp0, good
  pext     pext_mask, good, good

  // 3. Shuffle the elements in `vals` such that all good elements
  //    are ordered consecutivelly, and store them.
  movq   good, table_idx
  shl    $4, table_idx
  movdqu (tab, table_idx), shuffle_out_mask
  pshufb shuffle_out_mask, vals
  movdqu vals, (%rsp, cnt, 2)

  // Update the counter and check if we are done.
  popcnt good, good
  addq good, cnt

  cmpq $256, cnt
  jnb rej_uniform_asm_final_copy

  addq $12, pos
  cmpq pos, len
  ja rej_uniform_asm_loop_start

Lrej_uniform_asm_final_copy:
  // Copy up to 256 values to the output: min(cnt, 256).
  mov   $256, %rcx
  cmp   $256, cnt
  cmova %rcx, cnt

  movq %rsp, %rsi
  movq cnt, %rcx
  shlq $1, %rcx
  rep  movsb

  addq $STACK_SIZE, %rsp
  .cfi_adjust_cfa_offset -(STACK_SIZE)
  ret
  .cfi_endproc

/* To facilitate single-compilation-unit (SCU) builds, undefine all macros.
 * Don't modify by hand -- this is auto-generated by scripts/autogen. */
#undef in
#undef out
#undef len
#undef tab
#undef cnt
#undef pos
#undef good
#undef pext_mask
#undef table_idx
#undef bound
#undef temp0
#undef temp1
#undef vals
#undef shuffle_out_mask
#undef shuffle_in_mask
#undef and_mask
#undef STACK_SIZE

/* simpasm: footer-start */
#endif /* MLK_ARITH_BACKEND_X86_64_DEFAULT && !MLK_CONFIG_MULTILEVEL_NO_SHARED \
        */
