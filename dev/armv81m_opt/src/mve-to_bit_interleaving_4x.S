///
/// Copyright (c) 2025 Arm Limited
/// SPDX-License-Identifier: Apache-2.0 OR MIT OR ISC
///

#include "../../../../common.h"
#if defined(MLK_FIPS202_ARMV81M_NEED_X4) && \
    !defined(MLK_CONFIG_MULTILEVEL_NO_SHARED)

 .thumb
 .syntax unified
.text

.macro interleave_odds x, t
    vshl.u32    \t, \x, #0
    vshl.u8     u, \t, #2
    vsri.u8     \t, u, #1
    vshl.u8     u, \t, #3
    vsri.u8     \t, u, #2
    vshl.u8     u, \t, #4
    vsri.u8     \t, u, #3
    vshl.u16    u, \t, #8
    vsri.u8     \t, u, #4
    vshl.u32    u, \t, #16
    vsri.u16    \t, u, #8

.endm

.macro interleave_evens x, t
    vshl.u32    \t, \x, #0
    vshr.u8     u, \t, #2
    vsli.u8     \t, u, #1
    vshr.u8     u, \t, #3
    vsli.u8     \t, u, #2
    vshr.u8     u, \t, #4
    vsli.u8     \t, u, #3
    vshr.u16    u, \t, #8
    vsli.u8     \t, u, #4
    vshr.u32    u, \t, #16
    vsli.u16    \t, u, #8
.endm

.align 8
.type MLK_ASM_NAMESPACE(to_bit_interleaving_4x), %function
.global MLK_ASM_NAMESPACE(to_bit_interleaving_4x)
MLK_ASM_FN_SYMBOL(to_bit_interleaving_4x)
    push	{r4 - r11, lr}
    vpush   {d8 - d15}
        to_bit_interleaving_4x_start:
                                    // Instructions:    48
                                    // Expected cycles: 95
                                    // Expected IPC:    0.51
                                    //
                                    // Cycle bound:     95.0
                                    // IPC bound:       0.51
                                    //
                                    // Wall time:     0.07s
                                    // User time:     0.07s
                                    //
                                    // -------------------------------------- cycle (expected) -------------------------------------->
                                    // 0                        25                       50                       75
                                    // |------------------------|------------------------|------------------------|-------------------
        vshl.u32 q7, q0, #0         // *..............................................................................................
        vshl.u32 q2, q0, #0         // ..*............................................................................................
        vshl.u32 q6, q1, #0         // ....*..........................................................................................
        vshl.u32 q0, q1, #0         // ......*........................................................................................
        vshl.u8 q3, q7, #2          // ........*......................................................................................
        vsri.u8 q7, q3, #1          // ..........*....................................................................................
        vshr.u8 q1, q2, #2          // ............*..................................................................................
        vsli.u8 q2, q1, #1          // ..............*................................................................................
        vshl.u8 q5, q6, #2          // ................*..............................................................................
        vsri.u8 q6, q5, #1          // ..................*............................................................................
        vshr.u8 q4, q0, #2          // ....................*..........................................................................
        vsli.u8 q0, q4, #1          // ......................*........................................................................
        vshl.u8 q5, q7, #3          // ........................*......................................................................
        vsri.u8 q7, q5, #2          // ..........................*....................................................................
        vshr.u8 q1, q2, #3          // ............................*..................................................................
        vsli.u8 q2, q1, #2          // ..............................*................................................................
        vshl.u8 q3, q6, #3          // ................................*..............................................................
        vsri.u8 q6, q3, #2          // ..................................*............................................................
        vshr.u8 q5, q0, #3          // ....................................*..........................................................
        vsli.u8 q0, q5, #2          // ......................................*........................................................
        vshl.u8 q1, q7, #4          // ........................................*......................................................
        vsri.u8 q7, q1, #3          // ..........................................*....................................................
        vshr.u8 q5, q2, #4          // ............................................*..................................................
        vsli.u8 q2, q5, #3          // ..............................................*................................................
        vshl.u8 q5, q6, #4          // ................................................*..............................................
        vsri.u8 q6, q5, #3          // ..................................................*............................................
        vshr.u8 q5, q0, #4          // ....................................................*..........................................
        vsli.u8 q0, q5, #3          // ......................................................*........................................
        vshl.u16 q4, q7, #8         // ........................................................*......................................
        vsri.u8 q7, q4, #4          // ..........................................................*....................................
        vshr.u16 q3, q2, #8         // ............................................................*..................................
        vsli.u8 q2, q3, #4          // ..............................................................*................................
        vshl.u16 q1, q6, #8         // ................................................................*..............................
        vsri.u8 q6, q1, #4          // ..................................................................*............................
        vshr.u16 q3, q0, #8         // ....................................................................*..........................
        vsli.u8 q0, q3, #4          // ......................................................................*........................
        vshl.u32 q3, q7, #16        // ........................................................................*......................
        vsri.u16 q7, q3, #8         // ..........................................................................*....................
        vshr.u32 q4, q2, #16        // ............................................................................*..................
        vsli.u16 q2, q4, #8         // ..............................................................................*................
        vshl.u32 q3, q6, #16        // ................................................................................*..............
        vsri.u16 q6, q3, #8         // ..................................................................................*............
        vshr.u32 q4, q0, #16        // ....................................................................................*..........
        vsli.u16 q0, q4, #8         // ......................................................................................*........
        vsri.32 q6, q7, #16         // ........................................................................................*......
        vsli.32 q2, q0, #16         // ..........................................................................................*....
        vshl.u32 q1, q6, #0         // ............................................................................................*..
        vshl.u32 q0, q2, #0         // ..............................................................................................*

                                             // -------------------------------------- cycle (expected) -------------------------------------->
                                             // 0                        25                       50                       75
                                             // |------------------------|------------------------|------------------------|-------------------
        // vshl.u32    E0, q0, #0            // ..*............................................................................................
        // vshr.u8     u, E0, #2             // ............*..................................................................................
        // vsli.u8     E0, u, #1             // ..............*................................................................................
        // vshr.u8     u, E0, #3             // ............................*..................................................................
        // vsli.u8     E0, u, #2             // ..............................*................................................................
        // vshr.u8     u, E0, #4             // ............................................*..................................................
        // vsli.u8     E0, u, #3             // ..............................................*................................................
        // vshr.u16    u, E0, #8             // ............................................................*..................................
        // vsli.u8     E0, u, #4             // ..............................................................*................................
        // vshr.u32    u, E0, #16            // ............................................................................*..................
        // vsli.u16    E0, u, #8             // ..............................................................................*................
        // vshl.u32    E1, q1, #0            // ......*........................................................................................
        // vshr.u8     u, E1, #2             // ....................*..........................................................................
        // vsli.u8     E1, u, #1             // ......................*........................................................................
        // vshr.u8     u, E1, #3             // ....................................*..........................................................
        // vsli.u8     E1, u, #2             // ......................................*........................................................
        // vshr.u8     u, E1, #4             // ....................................................*..........................................
        // vsli.u8     E1, u, #3             // ......................................................*........................................
        // vshr.u16    u, E1, #8             // ....................................................................*..........................
        // vsli.u8     E1, u, #4             // ......................................................................*........................
        // vshr.u32    u, E1, #16            // ....................................................................................*..........
        // vsli.u16    E1, u, #8             // ......................................................................................*........
        // vsli.32          E0, E1, #16      // ..........................................................................................*....
        // vshl.u32    O0, q0, #0            // *..............................................................................................
        // vshl.u8     u, O0, #2             // ........*......................................................................................
        // vsri.u8     O0, u, #1             // ..........*....................................................................................
        // vshl.u8     u, O0, #3             // ........................*......................................................................
        // vsri.u8     O0, u, #2             // ..........................*....................................................................
        // vshl.u8     u, O0, #4             // ........................................*......................................................
        // vsri.u8     O0, u, #3             // ..........................................*....................................................
        // vshl.u16    u, O0, #8             // ........................................................*......................................
        // vsri.u8     O0, u, #4             // ..........................................................*....................................
        // vshl.u32    u, O0, #16            // ........................................................................*......................
        // vsri.u16    O0, u, #8             // ..........................................................................*....................
        // vshl.u32    O1, q1, #0            // ....*..........................................................................................
        // vshl.u8     u, O1, #2             // ................*..............................................................................
        // vsri.u8     O1, u, #1             // ..................*............................................................................
        // vshl.u8     u, O1, #3             // ................................*..............................................................
        // vsri.u8     O1, u, #2             // ..................................*............................................................
        // vshl.u8     u, O1, #4             // ................................................*..............................................
        // vsri.u8     O1, u, #3             // ..................................................*............................................
        // vshl.u16    u, O1, #8             // ................................................................*..............................
        // vsri.u8     O1, u, #4             // ..................................................................*............................
        // vshl.u32    u, O1, #16            // ................................................................................*..............
        // vsri.u16    O1, u, #8             // ..................................................................................*............
        // vsri.32          O1, O0, #16      // ........................................................................................*......
        // vshl.u32         q0, E0, #0       // ..............................................................................................*
        // vshl.u32         q1, O1, #0       // ............................................................................................*..

        to_bit_interleaving_4x_exit:

    vpop {d8 - d15}
    pop {r4 - r11, pc}


#endif /* MLK_FIPS202_ARMV81M_NEED_X4 && !MLK_CONFIG_MULTILEVEL_NO_SHARED */
